### Daily Log
#### Day 4 - August 15, 2024

**Today's Focus:** Diving Deeper into Feature Engineering

**Resources Used:**
- ğŸ“– *Feature Engineering for Machine Learning* by Alice Zheng and Amanda Casari
- ğŸŒ [Kaggle - Feature Engineering Course](https://www.kaggle.com/learn/feature-engineering)
- ğŸŒ [Towards Data Science - A Comprehensive Guide to Feature Engineering](https://towardsdatascience.com/feature-engineering)

**Activities:**
- ğŸ“ Explored the importance of feature engineering in improving model performance.
- ğŸ“Œ Studied techniques like handling missing data, creating new features, and scaling data.

**Detailed Notes:**

ğŸ“ **Key Techniques in Feature Engineering:**
- **Handling Missing Data:** Imputation methods, such as mean, median, or mode replacement.
- **Creating New Features:** Combining existing features to create more informative ones.
- **Scaling and Normalization:** Ensuring features are on the same scale to improve model accuracy.

**Reflections:**
- Feature engineering is a critical step in the ML pipeline that can significantly impact the performance of models.

**Next Steps:**
- Practice feature engineering techniques on datasets from Kaggle to solidify understanding.
- Explore advanced techniques like feature selection and extraction.
